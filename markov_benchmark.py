#!/usr/bin/env python3

import os
import sys
import time
import random
import math

# --- Configuration ---
NUM_FILES = 100          # Number of files to create
WRITES_PER_FILE = 5      # Number of write operations per file
READS_PER_FILE = 10     # Number of read operations per file
DATA_SIZE_PER_WRITE = 1024 # Bytes to write in each write operation (1KB)
LISTDIR_ITERATIONS = 5   # Number of times to list the directory

# --- Helper Function ---
def format_size(size_bytes):
    """Converts bytes to a human-readable format."""
    if size_bytes == 0:
        return "0B"
    size_name = ("B", "KB", "MB", "GB", "TB", "PB", "EB", "ZB", "YB")
    # Handle potential log(0) or negative values if input is unexpected
    if size_bytes <= 0: return "0B"
    try:
        i = int(math.floor(math.log(size_bytes, 1024)))
        # Ensure index is within bounds
        i = max(0, min(i, len(size_name) - 1))
        p = math.pow(1024, i)
        s = round(size_bytes / p, 2)
        return f"{s} {size_name[i]}"
    except ValueError: # Fallback for edge cases
        return f"{size_bytes} B"


# --- Main Benchmark Function ---
def benchmark_fuse_filesystem(mountpoint):
    """
    Performs a longer benchmark on the FUSE filesystem, including sequential,
    reverse, and random read patterns after an initial write phase.

    NOTE: For predictive caching models (like Markov), ensure the model is
    trained on representative access patterns (potentially generated by a
    previous run of this script) before running this benchmark for meaningful
    performance evaluation. Start the FUSE filesystem with the trained model loaded.

    Args:
        mountpoint (str): Path where the FUSE filesystem is mounted.
    """

    if not os.path.isdir(mountpoint): # Check if it's a directory
        print(f"Error: Mountpoint '{mountpoint}' is not an existing directory.")
        sys.exit(1)
    # Check if mountpoint is actually mounted (best effort check)
    # Note: os.path.ismount might not work reliably for FUSE mounts on all OSs
    # if not os.path.ismount(mountpoint):
    #      print(f"Warning: '{mountpoint}' does not appear to be an active mount point based on os.path.ismount.")


    print("="*70)
    print(f"Starting Longer Benchmark on: {mountpoint}")
    print("="*70)
    print(f"Configuration:")
    print(f"  - Files to create:         {NUM_FILES}")
    print(f"  - Writes per file:         {WRITES_PER_FILE}")
    print(f"  - Reads per file:          {READS_PER_FILE}")
    print(f"  - Data size per write:     {format_size(DATA_SIZE_PER_WRITE)}")
    print(f"  - Directory list iterations: {LISTDIR_ITERATIONS}")
    total_data_written_expected = NUM_FILES * WRITES_PER_FILE * DATA_SIZE_PER_WRITE
    final_file_size_expected = WRITES_PER_FILE * DATA_SIZE_PER_WRITE
    total_data_read_expected_per_pattern = NUM_FILES * READS_PER_FILE * final_file_size_expected
    print(f"  - Expected final size/file: {format_size(final_file_size_expected)}")
    print(f"  - Total data to write:     {format_size(total_data_written_expected)}")
    print(f"  - Total data to read (each pattern): {format_size(total_data_read_expected_per_pattern)}")
    print("-"*70)

    # --- File Paths ---
    file_paths = [os.path.join(mountpoint, f"benchmark_file_{i:04d}.dat") for i in range(NUM_FILES)]

    # --- Cleanup Old Files (Optional but recommended for clean runs) ---
    print("Attempting to clean up old benchmark files...")
    cleanup_count = 0
    for p in file_paths:
        if os.path.exists(p):
            try:
                os.remove(p)
                cleanup_count += 1
            except Exception as e:
                print(f"  Warning: Could not remove old file {p}: {e}")
    if cleanup_count > 0: print(f"  Removed {cleanup_count} old files.")
    # Ensure mountpoint dir exists after potential cleanup
    if not os.path.exists(mountpoint):
        os.makedirs(mountpoint) # Recreate if cleanup removed it somehow (unlikely)

    # --- Write Phase ---
    print(f"[1] Starting Write Phase ({NUM_FILES} files)...")
    start_time = time.time()
    total_bytes_written_actual = 0
    write_errors = 0

    for i, file_path in enumerate(file_paths):
        try:
            # Using 'wb' ensures the file is overwritten/created fresh for each benchmark run
            with open(file_path, 'wb') as f:
                file_content_size = 0
                for w in range(WRITES_PER_FILE):
                    data_chunk = os.urandom(DATA_SIZE_PER_WRITE)
                    bytes_written = f.write(data_chunk)
                    if bytes_written != DATA_SIZE_PER_WRITE:
                        print(f"  Warning: Short write on {file_path}, iteration {w}. Expected {DATA_SIZE_PER_WRITE}, got {bytes_written}")
                    total_bytes_written_actual += bytes_written
                    file_content_size += bytes_written

            # Sanity check file size after writing (optional)
            # written_size = os.path.getsize(file_path)
            # if written_size != file_content_size:
            #      print(f"  Warning: Size mismatch after writing {file_path}. Expected {file_content_size}, actual {written_size}")

            if (i + 1) % (NUM_FILES // 10 or 1) == 0 or i == NUM_FILES - 1: # Progress indicator (approx 10 updates)
                print(f"  Written {i + 1}/{NUM_FILES} files...")
        except Exception as e:
            print(f"Error writing to {file_path}: {e}")
            write_errors += 1
            # Decide whether to continue or stop on error
            # continue

    write_time = time.time() - start_time
    print(f"Write Phase completed in {write_time:.2f} seconds.")
    print(f"  Total bytes written: {format_size(total_bytes_written_actual)}")
    if write_errors > 0: print(f"  WARNING: Encountered {write_errors} write errors.")
    print("-"*70)
    time.sleep(1) # Small pause

    # --- Read Phase Functions ---
    def run_read_phase(phase_num, pattern_name, file_order_indices):
        print(f"[{phase_num}] Starting Read Phase ({pattern_name})...")
        phase_start_time = time.time()
        total_bytes_read_actual = 0
        read_errors = 0

        for count, i in enumerate(file_order_indices):
            file_path = file_paths[i]
            try:
                # Check if file exists before attempting to read multiple times
                if not os.path.exists(file_path):
                    print(f"Error: File disappeared before read: {file_path}")
                    read_errors += 1
                    continue # Skip this file

                for r in range(READS_PER_FILE):
                    with open(file_path, 'rb') as f:
                        content = f.read() # Read the whole file
                        read_len = len(content)
                        # Optional: Verify size roughly matches expected size
                        if read_len != final_file_size_expected:
                            print(f"  Warning: Size mismatch reading {file_path} (read {r+1}/{READS_PER_FILE}). Expected {final_file_size_expected}, got {read_len}")
                        total_bytes_read_actual += read_len

                if (count + 1) % (NUM_FILES // 10 or 1) == 0 or count == NUM_FILES - 1: # Progress indicator
                    print(f"  Read {count + 1}/{NUM_FILES} files in {pattern_name} order...")
            except FileNotFoundError:
                # Should be caught by os.path.exists check above, but handle just in case
                print(f"Error: File not found during read phase: {file_path}")
                read_errors += 1
            except Exception as e:
                print(f"Error reading {file_path}: {e}")
                read_errors += 1

        phase_time = time.time() - phase_start_time
        print(f"{pattern_name} Read Phase completed in {phase_time:.2f} seconds.")
        print(f"  Total bytes read: {format_size(total_bytes_read_actual)}")
        if read_errors > 0: print(f"  WARNING: Encountered {read_errors} read errors.")
        print("-"*70)
        time.sleep(1) # Small pause between read phases

    # --- Execute Read Phases ---
    # 2. Sequential Read
    sequential_indices = list(range(NUM_FILES))
    run_read_phase(2, "Sequential", sequential_indices)

    # 3. Reverse Read
    reverse_indices = list(range(NUM_FILES))
    reverse_indices.reverse()
    run_read_phase(3, "Reverse", reverse_indices)

    # 4. Random Read
    random_indices = list(range(NUM_FILES))
    random.shuffle(random_indices)
    run_read_phase(4, "Random", random_indices)

    # --- Directory Listing Phase ---
    print(f"[5] Starting Directory Listing Phase ({LISTDIR_ITERATIONS} iterations)...")
    start_time = time.time()
    list_errors = 0
    listed_files_count = 0
    for i in range(LISTDIR_ITERATIONS):
        try:
            files = os.listdir(mountpoint)
            listed_files_count = len(files) # Get count from last successful list
            # print(f"  Iteration {i+1}: Found {len(files)} entries.") # Optional verbose output
        except Exception as e:
            print(f"Error listing directory {mountpoint} on iteration {i+1}: {e}")
            list_errors += 1

    list_time = time.time() - start_time
    print(f"Directory Listing Phase completed in {list_time:.2f} seconds.")
    # Adjust expected count if hidden files might exist (.DS_Store etc)
    print(f"  Entries found in last listing: {listed_files_count} (Expected ~ {NUM_FILES})")
    if list_errors > 0: print(f"  WARNING: Encountered {list_errors} listdir errors.")
    print("-"*70)

    # --- Trigger Shutdown ---
    print("[6] Triggering FUSE shutdown to display stats...")
    # Ensure shutdown file is created where the FUSE script runs (usually CWD)
    shutdown_file = os.path.join(os.getcwd(), "shutdown")
    try:
        with open(shutdown_file, 'w') as f:
            f.write("shutdown")
        print(f"Created {shutdown_file}. Waiting for FUSE process to react...")
    except Exception as e:
        print(f"Error creating shutdown file {shutdown_file}: {e}")
        print("Please manually stop the FUSE process if needed.")
        sys.exit(1) # Exit if we can't signal shutdown

    # Give the FUSE process time to detect the file, print stats, and unmount
    print("Benchmark finished. Check FUSE process output for statistics.")
    print("Waiting a few seconds before exiting benchmark script...")
    time.sleep(5) # Increased sleep

# --- Main Execution Block ---
if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage: python3 longer_benchmark.py <mountpoint>")
        sys.exit(1)

    mount_path = sys.argv[1]
    benchmark_fuse_filesystem(mount_path)